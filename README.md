# University Prospectus RAG Chatbot Backend

This project is a **Retrieval-Augmented Generation (RAG) backend** built
with Flask, Azure OpenAI, and Azure Cognitive Search.\
It enables conversational Q&A over university documents with
session-based chat history and observability.

------------------------------------------------------------------------

## Features

-   Semantic & vector search with Azure Cognitive Search\
-   Query rewriting using conversation history\
-   Azure OpenAI (GPT) for answer generation\
-   Session-based chat memory\
-   Token usage logging\
-   Arize AX tracing (OpenInference)\
-   REST API for frontend integration\
-   Docker support

------------------------------------------------------------------------

## Project Structure

    .
    ├── app.py
    ├── RAG.py
    ├── Dockerfile
    ├── docker-compose.yml
    ├── .env.example
    ├── requirements.txt
    └── README.md

------------------------------------------------------------------------

## Environment Variables

Create a `.env` file:

``` env
COGNITIVESEARCHCONNECTOR5_API_KEY=...
COGNITIVESEARCHCONNECTOR5_API_BASE=...
COGNITIVESEARCHCONNECTOR5_INDEX_NAME=...

AZURE_OPENAI_ENDPOINT=...
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_DEPLOYMENT_NAME=...
AZURE_OPENAI_API_VERSION=...

ARIZE_API_KEY=...
ARIZE_SPACE_ID=...
VERBOSE=true
```

------------------------------------------------------------------------

## Local Setup

``` bash
pip install -r requirements.txt
python app.py
```

API runs on:

    http://localhost:8000/chat

------------------------------------------------------------------------

## API Example

**Request**

``` json
{
  "chatInput": "Which faculties exist at UDG?"
}
```

**Response**

``` json
{
  "answer": "...",
  "sessionId": "uuid"
}
```

------------------------------------------------------------------------

## Docker

### Build

``` bash
docker build -t university-rag-backend .
```

### Run

``` bash
docker run -p 8000:8000 --env-file .env university-rag-backend
```

### Docker Compose

``` bash
docker compose up --build
```

------------------------------------------------------------------------

## RAG Pipeline

1.  User question\
2.  Query rewriting using chat history\
3.  Vector search in Azure Cognitive Search\
4.  Context injected into GPT prompt\
5.  Answer generated by Azure OpenAI

------------------------------------------------------------------------

## Notes

-   Chat history is stored in-memory (for production use Redis/DB)\
-   Do not commit `.env`\
-   Restrict API keys and enable CORS properly in production


